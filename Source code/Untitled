# we create two instances with the same arguments
data_gen_args = dict(featurewise_center=True,
                     featurewise_std_normalization=True,
                     rotation_range=90.,
                     width_shift_range=0.1,
                     height_shift_range=0.1,
                     zoom_range=0.2)
image_datagen = ImageDataGenerator(**data_gen_args)
mask_datagen = ImageDataGenerator(**data_gen_args)

# Provide the same seed and keyword arguments to the fit and flow methods
seed = 1
image_datagen.fit(images, augment=True, seed=seed)
mask_datagen.fit(masks, augment=True, seed=seed)

image_generator = image_datagen.flow_from_directory(
    'data/images',
    class_mode=None,
    seed=seed)

mask_generator = mask_datagen.flow_from_directory(
    'data/masks',
    class_mode=None,
    seed=seed)

# combine generators into one which yields image and masks
train_generator = zip(image_generator, mask_generator)

model.fit_generator(
    train_generator,
    steps_per_epoch=2000,
    epochs=50)
Next  Previous








train_generator, train_steps_per_epoch, \
      val_generator, val_steps_per_epoch = dataset.create_generators(
          args.datadir, args.batch_size,
          validation_split=args.validation_split,
          mask=args.classes,
          shuffle_train_val=args.shuffle_train_val,
          shuffle=args.shuffle,
          seed=args.seed,
          normalize_images=args.normalize,
          augment_training=args.augment_training,
          augment_validation=args.augment_validation,
          augmentation_args=augmentation_args)


              datagen = ImageDataGenerator(
                  rotation_range = 180,
                  width_shift_range = 0.1,
                  height_shift_range = 0.1,
                  rescale=1./255,
                  shear_range=0.1,
                  zoom_range = 0.1,
                  horizontal_flip = True,
                  vertical_flip = True,
                  fill_mode='nearest')

              config = tf.ConfigProto(allow_soft_placement=True)
              config.gpu_options.allocator_type = 'BFC'
              config.gpu_options.per_process_gpu_memory_fraction = 0.40

  # get image dimensions from first batch
  images, masks = next(train_generator)
  _, height, width, channels = images.shape
  #_, _, _, classes = masks.shape


  def batch_generator(batch_size):
      images_path = '/home/barskaiy/AxSegmenta/data/patched_data_224x224/images/'
      masks_path = '/home/barskaiy/AxSegmenta/data/patched_data_224x224/masks/'
      # we create two instances with the same arguments
      data_gen_args = dict(featurewise_center=True,
                       featurewise_std_normalization=True,
                       rotation_range=180.,
                       width_shift_range=0.0,
                       height_shift_range=0.0,
                       zoom_range=0.0)
      image_datagen = ImageDataGenerator(**data_gen_args)
      mask_datagen = ImageDataGenerator(**data_gen_args)

      # Provide the same seed and keyword arguments to the fit and flow methods
      seed = 1
      image_generator = image_datagen.flow_from_directory(images_path,
                                                          class_mode=None,
                                                          seed=seed,
                                                          target_size=(224, 224),
                                                          batch_size = batch_size)

      mask_generator = mask_datagen.flow_from_directory(masks_path,
                                                        class_mode=None,
                                                        seed=seed,
                                                        target_size=(224, 224),
                                                        batch_size = batch_size)

      # combine generators into one which yields image and masks
      train_generator = zip(image_generator, mask_generator)
      return train_generator
